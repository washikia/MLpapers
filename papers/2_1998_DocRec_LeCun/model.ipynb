{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import import_ipynb\n",
    "from utils import generate_parameter_vector, scaled_tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3769, 0.4346, 0.1880, 0.9186],\n",
       "          [0.7414, 0.3024, 0.8848, 0.4306],\n",
       "          [0.3657, 0.5118, 0.7352, 0.2907],\n",
       "          [0.8290, 0.3280, 0.5288, 0.2291]],\n",
       "\n",
       "         [[0.1441, 0.9879, 0.5977, 0.2393],\n",
       "          [0.4624, 0.5259, 0.4718, 0.6364],\n",
       "          [0.0130, 0.8579, 0.7141, 0.9142],\n",
       "          [0.8387, 0.5812, 0.9526, 0.0079]]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand([1, 2, 4, 4])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[[0.3769, 0.4346],\n",
       "            [0.1880, 0.9186]],\n",
       "\n",
       "           [[0.7414, 0.3024],\n",
       "            [0.8848, 0.4306]]],\n",
       "\n",
       "\n",
       "          [[[0.3657, 0.5118],\n",
       "            [0.7352, 0.2907]],\n",
       "\n",
       "           [[0.8290, 0.3280],\n",
       "            [0.5288, 0.2291]]]],\n",
       "\n",
       "\n",
       "\n",
       "         [[[[0.1441, 0.9879],\n",
       "            [0.5977, 0.2393]],\n",
       "\n",
       "           [[0.4624, 0.5259],\n",
       "            [0.4718, 0.6364]]],\n",
       "\n",
       "\n",
       "          [[[0.0130, 0.8579],\n",
       "            [0.7141, 0.9142]],\n",
       "\n",
       "           [[0.8387, 0.5812],\n",
       "            [0.9526, 0.0079]]]]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.view(1,2,4//2,2,4//2,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.8552, 2.4220],\n",
       "          [2.0345, 1.7838]],\n",
       "\n",
       "         [[2.1203, 1.9452],\n",
       "          [2.2908, 2.5887]]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.sum(x,dim=(3,5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUSTOM_POOLING(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.weights = nn.Parameter(torch.randn(out_channels))\n",
    "        self.bias = nn.Parameter(torch.randn(out_channels))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.size()\n",
    "        assert H%2==0 and W%2==0\n",
    "\n",
    "        x = x.view(B, C, H//2, 2, W//2, 2)\n",
    "        x = torch.sum(x, dim=(3,5))\n",
    "        x = x * self.weights.view(1,-1,1,1) + self.bias.view(1,-1,1,1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2035,  2.1864],\n",
       "          [ 0.5668,  1.7187]],\n",
       "\n",
       "         [[ 0.9794,  1.4307],\n",
       "          [ 2.9042,  2.5593]],\n",
       "\n",
       "         [[ 0.7545,  4.1771],\n",
       "          [-1.8419, -1.2931]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn([1, 3, 4, 4])\n",
    "y = CUSTOM_POOLING(1,3)\n",
    "y.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1 = [\n",
    "    [0,1,2],\n",
    "    [1,2,3],\n",
    "    [2,3,4],\n",
    "    [3,4,5],\n",
    "    [4,5,0],\n",
    "    [5,0,1],\n",
    "    [0,1,2,3],\n",
    "    [1,2,3,4],\n",
    "    [2,3,4,5],\n",
    "    [3,4,5,0],\n",
    "    [4,5,0,1],\n",
    "    [5,0,1,2],\n",
    "    [0,1,3,4],\n",
    "    [1,2,4,5],\n",
    "    [0,2,3,5],\n",
    "    [0,1,2,3,4,5]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPARSE_CONV(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, connection_scheme):\n",
    "        super().__init__()\n",
    "        self.connection_scheme = connection_scheme\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Conv2d(len(S2_channels), 1, kernel_size) for S2_channels in connection_scheme]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = []\n",
    "        for i, S2_channels in enumerate(self.connection_scheme):\n",
    "            output.append(\n",
    "                self.convs[i](x[:, S2_channels, :, :])\n",
    "            )\n",
    "        \n",
    "        return torch.cat(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 10, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 6, 14, 14)\n",
    "m = SPARSE_CONV(6, 16, 5, connection_scheme=table1)\n",
    "y = m(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0328,  0.2197, -1.2524],\n",
       "        [ 0.5077,  0.5836,  1.6626]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.randn(2, 3, 1, 1)\n",
    "temp.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1., -1.,  1.],\n",
       "        [-1.,  1., -1.,  1.],\n",
       "        [ 1., -1.,  1., -1.],\n",
       "        [-1.,  1.,  1., -1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([generate_parameter_vector(0.5, 4) for _ in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBF(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.parameter_vector = nn.Parameter(\n",
    "            torch.stack(\n",
    "                [generate_parameter_vector(0.2, length=in_channels) for _ in range(out_channels)]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # print('x ', x.shape)\n",
    "        # print('param: ', self.parameter_vector.shape)\n",
    "        # print('x-param: ', (x-self.parameter_vector).shape)\n",
    "        # print('sum(x-param:) ', torch.sum(x-self.parameter_vector, dim=1), torch.sum((x-self.parameter_vector),dim=1, keepdim=True).shape)\n",
    "        output = torch.sum(torch.square(x-self.parameter_vector), dim=1, keepdim=True)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "start\n",
      "\n",
      "\n",
      "x  torch.Size([4])\n",
      "param:  torch.Size([3, 4])\n",
      "x-param:  torch.Size([3, 4])\n",
      "\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "sum(x-param:)  tensor([-0.1607, -2.1607, -0.1607], grad_fn=<SumBackward1>) torch.Size([3, 1])\n",
      "tensor([[2.2292],\n",
      "        [1.5074],\n",
      "        [5.2928]], grad_fn=<SumBackward1>) torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4)\n",
    "m = RBF(4, 3)\n",
    "y = m(x)\n",
    "print(y, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOCK_LENET5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.C1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n",
    "        self.S2 = CUSTOM_POOLING(in_channels=6, out_channels=6)\n",
    "        self.C3 = SPARSE_CONV(in_channels=6, out_channels=16, kernel_size=5, connection_scheme=table1)\n",
    "        self.S4 = CUSTOM_POOLING(in_channels=16, out_channels=16)\n",
    "        self.C5 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5)\n",
    "        self.F6 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.RBF = RBF(in_channels=84, out_channels=10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = scaled_tanh(input=self.C1(x))\n",
    "        x = scaled_tanh(input=self.S2(x))\n",
    "        x = scaled_tanh(input=self.C3(x))\n",
    "        x = scaled_tanh(input=self.S4(x))\n",
    "        x = scaled_tanh(input=self.C5(x))\n",
    "        x = x.squeeze()\n",
    "        print(x.shape)\n",
    "        x = scaled_tanh(input=self.F6(x))\n",
    "        print(x.shape)\n",
    "        output = self.RBF(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 120, 1, 1])\n",
      "torch.Size([120])\n",
      "torch.Size([84])\n",
      "\n",
      "\n",
      "start\n",
      "\n",
      "\n",
      "x  torch.Size([84])\n",
      "param:  torch.Size([10, 84])\n",
      "x-param:  torch.Size([10, 84])\n",
      "\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "sum(x-param:)  tensor([-37.9054, -57.9054, -51.9054, -55.9054, -47.9054, -41.9054, -45.9054,\n",
      "        -45.9054, -55.9054, -61.9054], grad_fn=<SumBackward1>) torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand(1,1,32,32)\n",
    "model = MOCK_LENET5()\n",
    "output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[177.2170],\n",
       "        [181.4866],\n",
       "        [149.2645],\n",
       "        [164.0868],\n",
       "        [164.3589],\n",
       "        [159.2939],\n",
       "        [157.3618],\n",
       "        [171.2735],\n",
       "        [178.8741],\n",
       "        [164.8284]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpapers_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
