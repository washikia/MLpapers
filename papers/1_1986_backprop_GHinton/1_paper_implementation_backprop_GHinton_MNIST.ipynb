{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFEfEG4y6ZJk",
        "outputId": "9ecfeb95-9cd1-41b7-ef38-57617caddb0b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2M0QY-d6UTOe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"using device {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DHNAzzN8TZs",
        "outputId": "d2134ee5-2f52-46be-a24f-e3721cdccd56"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transforms - convert to tensor, normalize pixel values\n",
        "\n",
        "transformation = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5)\n",
        "])"
      ],
      "metadata": {
        "id": "bdvOqP_HZJaK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data download and dataloader\n",
        "\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transformation)\n",
        "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transformation)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH6otPkEaKC-",
        "outputId": "7b829250-cd18-41bc-ed4e-6581f8f63940"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 15.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 460kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.41MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.51MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleNN, self).__init__()\n",
        "    self.fc1 = nn.Linear(28*28, 128)\n",
        "    self.dropout1 = nn.Dropout(0.1)\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.dropout2 = nn.Dropout(0.1)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, input):\n",
        "    x = input.view(-1, 28*28)\n",
        "    x = nn.functional.relu(self.fc1(x))\n",
        "    # x = self.dropout1(x)\n",
        "    x = nn.functional.relu(self.fc2(x))\n",
        "    # x = self.dropout2(x)\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "comCZSs8iBSg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleNN().to(device)"
      ],
      "metadata": {
        "id": "pnlDz73Dr6bd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "bLhEaT5Bt8PR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for inputs, lables in train_loader:\n",
        "    inputs, lables = inputs.to(device), lables.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(inputs)\n",
        "    loss = criterion(output, lables)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "    total += lables.size(0)\n",
        "    correct += (predicted == lables).sum().item()\n",
        "\n",
        "  train_loss = running_loss / len(train_loader)\n",
        "  train_accuracy = 100 * correct / total\n",
        "  print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0c5C87_v-LJ",
        "outputId": "ad6041eb-1099-4abe-fa29-04e1e5a0f335"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 2.2442, Train Accuracy: 15.21%\n",
            "Epoch 2/10, Train Loss: 2.0414, Train Accuracy: 38.55%\n",
            "Epoch 3/10, Train Loss: 1.6582, Train Accuracy: 61.03%\n",
            "Epoch 4/10, Train Loss: 1.2021, Train Accuracy: 72.03%\n",
            "Epoch 5/10, Train Loss: 0.8823, Train Accuracy: 78.15%\n",
            "Epoch 6/10, Train Loss: 0.7095, Train Accuracy: 81.84%\n",
            "Epoch 7/10, Train Loss: 0.6083, Train Accuracy: 83.98%\n",
            "Epoch 8/10, Train Loss: 0.5422, Train Accuracy: 85.45%\n",
            "Epoch 9/10, Train Loss: 0.4966, Train Accuracy: 86.43%\n",
            "Epoch 10/10, Train Loss: 0.4634, Train Accuracy: 87.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for inputs, lables in test_loader:\n",
        "    inputs, lables = inputs.to(device), lables.to(device)\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += lables.size(0)\n",
        "    correct += (predicted == lables).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUe7RLfT5aTB",
        "outputId": "805d7b2d-c070-411b-bdc4-75633d078408"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 88.23%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD 10 epoch\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for inputs, lables in test_loader:\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += lables.size(0)\n",
        "    correct += (predicted == lables).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "W-DAMr7m6LqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD 10 epochs with dropout 0.2 CUDA\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for inputs, lables in test_loader:\n",
        "    inputs, lables = inputs.to(device), lables.to(device)\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += lables.size(0)\n",
        "    correct += (predicted == lables).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "P5GjJXya7SgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD 10 epochs with dropout 0.1 CUDA\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for inputs, lables in test_loader:\n",
        "    inputs, lables = inputs.to(device), lables.to(device)\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += lables.size(0)\n",
        "    correct += (predicted == lables).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "hNSXOVk-97mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD 10 epochs without dropout CUDA\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for inputs, lables in test_loader:\n",
        "    inputs, lables = inputs.to(device), lables.to(device)\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += lables.size(0)\n",
        "    correct += (predicted == lables).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "fuKJU0xL-rXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/washikia/MLpapers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MuShws5CAu_",
        "outputId": "f18049a4-9b26-4839-e3a1-3330965165e5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MLpapers'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 14 (delta 1), reused 12 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (14/14), 1.26 MiB | 28.13 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"washikuddin@kaist.ac.kr\"\n",
        "!git config --global user.name \"washikia\""
      ],
      "metadata": {
        "id": "H5_G3MOUCKyZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MLpapers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgmsfAI1RP5o",
        "outputId": "92f2db2f-a0de-4d3d-e224-aceb516bf03f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MLpapers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote set-url origin https://washikia:<github token>@github.com/washikia/MLpapers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OudiDQyACOxa",
        "outputId": "94dfb892-2679-4622-98c8-d2bdb8bb4427"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: github: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../.."
      ],
      "metadata": {
        "id": "kHxZwoC7Tb2E",
        "outputId": "110b0882-dc84-4508-f4ef-e7275d35e657",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv drive/MyDrive/Colab_Notebooks/1_paper_implementation_backprop_GHinton_MNIST.ipynb MLpapers/papers/1_1986_backprop_GHinton"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a19IHVTDS2mF",
        "outputId": "4e7cdc9e-0371-44af-90f8-ee2c3a78ef3e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'drive/MyDrive/Colab_Notebooks/1_paper_implementation_backprop_GHinton_MNIST.ipynb': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MLpapers"
      ],
      "metadata": {
        "id": "SY89KmjxT-_U",
        "outputId": "ebfb9807-2469-4e31-fe95-ac06c29c30d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MLpapers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add papers/1_1986_backprop_GHinton/2_paper_implementation_backprop_GHinton_MNIST.ipynb"
      ],
      "metadata": {
        "id": "2FtKMfZZTZ6n"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"first paper, MNIST\""
      ],
      "metadata": {
        "id": "CEZuwbi9T3dR",
        "outputId": "06bfb8d9-f7d1-41ea-e64c-0e9820d490a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is ahead of 'origin/main' by 1 commit.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add/rm <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mdeleted:    papers/1_1986_backprop_GHinton/2_paper_implementation_backprop_GHinton_MNIST.ipynb\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mpapers/1_1986_backprop_GHinton/1_paper_implementation_backprop_GHinton_MNIST.ipynb\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main"
      ],
      "metadata": {
        "id": "capS6g45UQTL",
        "outputId": "efc530ad-4ebf-442b-b104-52b6fd408218",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git reset --hard HEAD~1"
      ],
      "metadata": {
        "id": "Sv-9-u1PUUNj",
        "outputId": "b3f1ed94-b599-4fbe-844e-a88dd44205fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HEAD is now at e27e528 Added notebook to paper1 folder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iyXP-zXGY40J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}